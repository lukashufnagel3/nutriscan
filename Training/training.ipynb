{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["======================================================<br>\n", "0. IMPORTS<br>\n", "======================================================"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import random\n", "import time\n", "import itertools\n", "from datetime import datetime\n", "import numpy as np\n", "import pandas as pd\n", "import ast\n", "from PIL import Image\n", "from tqdm.auto import tqdm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["PyTorch & Transformers"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset, DataLoader\n", "from torchvision import transforms\n", "from transformers import ViTForImageClassification, ViTImageProcessor\n", "from torch.optim import AdamW\n", "from torch.optim.lr_scheduler import ReduceLROnPlateau"]}, {"cell_type": "markdown", "metadata": {}, "source": ["klearn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split"]}, {"cell_type": "markdown", "metadata": {}, "source": ["======================================================<br>\n", "# 1. CONFIGURATION & CONSTANTS<br>\n", "======================================================"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SEED = 42 #Reproducibility\n", "random.seed(SEED)\n", "np.random.seed(SEED)\n", "torch.manual_seed(SEED)\n", "torch.cuda.manual_seed_all(SEED)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Paths (Adjust as needed for your environment)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATA_ROOT = \"/kaggle/input/nutrition14\"\n", "IMAGES_DIR = os.path.join(DATA_ROOT, \"data\")\n", "JSON_PATH = os.path.join(DATA_ROOT, \"filtered_data.json\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Output for checkpoints"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["OUTPUT_DIR = \"/kaggle/working/nutriscan_pytorch\"\n", "os.makedirs(OUTPUT_DIR, exist_ok=True)\n", "OUTPUT_CSV_PATH = os.path.join(OUTPUT_DIR, \"experiment_raw_data_M2.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Experiment Input (For resuming previous runs)<br>\n", "Set to None if this is the first run. Set to path if resuming."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["INPUT_CSV_PATH = \"/kaggle/input/results/experiment_raw_data_M2.csv\"\n", "# INPUT_CSV_PATH = None "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hyperparameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["IMAGE_SIZE = 224\n", "EPOCHS = 8\n", "WEIGHT_DECAY = 0.01\n", "PATIENCE = 3         # Early stopping patience\n", "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Device detected: {DEVICE}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["======================================================<br>\n", "2. DATA PROCESSING & MAPPING<br>\n", "======================================================"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Loading JSON:\", JSON_PATH)\n", "df = pd.read_json(JSON_PATH, dtype={'total_mass': 'float64'})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ensure label column is a list"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    df['label'] = df['label'].apply(ast.literal_eval)\n", "except Exception:\n", "    pass"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Filtered Semantic Map (Only the 14 requested classes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SEMANTIC_MAP = {\n", "    'CHICKEN': ['chicken'],\n", "    'BERRIES': ['berries', 'strawberry'],\n", "    'HIGH_SUGAR_FRUITS': ['fruit', 'apple', 'banana', 'orange'],\n", "    'COOKING_VEGS': ['cucumbers', 'broccoli', 'carrot', 'asparagus'],\n", "    'OATMEAL/CEREALS': ['cereal', 'oatmeal'],\n", "    'PORK': ['pork', 'bacon', 'ham', 'sausage'],\n", "    'BEEF': ['beef', 'steak', 'veal', 'meatball'],\n", "    'PIZZA': ['pizza'],\n", "    'POTATOES': ['potato', 'potatoes', 'fries', 'french fries', 'mashed potatoes'],\n", "    'LEAFY_GREENS': ['salad', 'vegetable', 'lettuce', 'spinach'],\n", "    'EGGS': ['eggs', 'egg', 'omelette', 'scrambled eggs', 'fried egg'],\n", "    'LEGUMES': ['beans', 'lentils', 'chickpeas', 'legume'],\n", "    'RICE': ['rice', 'risotto'],\n", "    'FISH': ['fish', 'salmon', 'tuna', 'cod', 'tilapia']\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def map_to_generic_class(ingredient_list):\n", "    \"\"\"Maps a list of ingredients to one of the 14 Generic Classes or OTHER.\"\"\"\n", "    if not isinstance(ingredient_list, list):\n", "        return 'OTHER'\n", "    for generic_class, keywords in SEMANTIC_MAP.items():\n", "        for keyword in keywords:\n", "            for ingredient in ingredient_list:\n", "                if keyword in ingredient.lower():\n", "                    return generic_class\n", "    return 'OTHER'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['generic_class'] = df['label'].apply(map_to_generic_class)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--- Balancing Strategy ---<br>\n", "1. Filter classes with enough samples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MIN_IMAGES_PER_CLASS = 150\n", "class_counts = df['generic_class'].value_counts()\n", "class_list = class_counts[class_counts >= MIN_IMAGES_PER_CLASS].index.tolist()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if 'OTHER' in class_list:\n", "    class_list.remove('OTHER')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Filter the dataframe to only include the valid 14 classes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["filtered_counts = class_counts[class_list]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["2. Undersample to the size of the smallest class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SAMPLES_PER_CLASS = int(filtered_counts.min()) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_list = []\n", "for class_name in class_list:\n", "    class_df = df[df['generic_class'] == class_name]\n", "    df_list.append(class_df.sample(SAMPLES_PER_CLASS, random_state=SEED))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_curato = pd.concat(df_list).sample(frac=1, random_state=SEED).reset_index(drop=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Encode labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_curato['label_code'] = df_curato['generic_class'].astype('category').cat.codes\n", "class_map = dict(enumerate(df_curato['generic_class'].astype('category').cat.categories))\n", "num_classes = len(class_map)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"--- Dataset Prepared ---\")\n", "print(f\"Total classes: {num_classes} (Target: 14)\")\n", "print(f\"Total images: {len(df_curato)}\")\n", "print(f\"Samples per class: {SAMPLES_PER_CLASS}\")\n", "print(\"Classes:\", list(class_map.values()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split train/val/test (70/15/15)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df, temp_df = train_test_split(df_curato, test_size=0.30, stratify=df_curato['label_code'], random_state=SEED)\n", "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label_code'], random_state=SEED)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--- Image Path Validation ---<br>\n", "Fixes broken links common in Kaggle datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Validating image paths...\")\n", "all_valid_rel_paths = set()\n", "for root, dirs, files in os.walk(IMAGES_DIR):\n", "    for f in files:\n", "        if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n", "            full_path = os.path.join(root, f)\n", "            rel_path = os.path.relpath(full_path, IMAGES_DIR)\n", "            all_valid_rel_paths.add(rel_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def fix_links(dataframe):\n", "    new_links = []\n", "    \n", "    def clean_path(path_str):\n", "        if not isinstance(path_str, str): return None\n", "        # Remove common prefixes\n", "        for prefix in ['./data/', 'data/', './']:\n", "            if path_str.startswith(prefix):\n", "                return path_str[len(prefix):]\n", "        return path_str\n", "    dataframe['image_link_cleaned'] = dataframe['image_link'].apply(clean_path)\n", "    for path in dataframe['image_link_cleaned']:\n", "        if path and path in all_valid_rel_paths:\n", "            new_links.append(path)\n", "        else:\n", "            new_links.append(None)\n", "    dataframe['image_link'] = new_links\n", "    return dataframe[dataframe['image_link'].notnull()].reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df = fix_links(train_df)\n", "val_df   = fix_links(val_df)\n", "test_df  = fix_links(test_df)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Final Train size: {len(train_df)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["======================================================<br>\n", "3. DATASET CLASS & TRANSFORMS<br>\n", "======================================================"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["processor = ViTImageProcessor.from_pretrained(\"nateraw/food\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_transform = transforms.Compose([\n", "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n", "    transforms.RandomHorizontalFlip(),\n", "    transforms.RandomRotation(15),\n", "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["val_transform = transforms.Compose([\n", "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class NutritionDataset(Dataset):\n", "    def __init__(self, df, directory, transform):\n", "        self.df = df.reset_index(drop=True)\n", "        self.dir = directory\n", "        self.transform = transform\n", "    def __len__(self):\n", "        return len(self.df)\n", "    def __getitem__(self, idx):\n", "        row = self.df.iloc[idx]\n", "        img_path = os.path.join(self.dir, row['image_link'])\n", "        image = Image.open(img_path).convert(\"RGB\")\n", "        if self.transform:\n", "            image = self.transform(image)\n", "        label = int(row['label_code'])\n", "        return image, label"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_ds = NutritionDataset(train_df, directory=IMAGES_DIR, transform=train_transform)\n", "val_ds   = NutritionDataset(val_df, directory=IMAGES_DIR, transform=val_transform)\n", "test_ds  = NutritionDataset(test_df, directory=IMAGES_DIR, transform=val_transform)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["datasets = (train_ds, val_ds, test_ds)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["======================================================<br>\n", "4. TRAINING FUNCTION<br>\n", "======================================================"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_seed(seed_value):\n", "    random.seed(seed_value)\n", "    np.random.seed(seed_value)\n", "    torch.manual_seed(seed_value)\n", "    torch.cuda.manual_seed_all(seed_value)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_experiment(lr, batch_size, run_seed, datasets, num_classes):\n", "    \"\"\"\n", "    Runs a single experiment. \n", "    Returns the Validation Accuracy of the LAST epoch (final state).\n", "    \"\"\"\n", "    start_time = time.time()\n", "    \n", "    # 1. Setup\n", "    print(f\"--- Starting Run: LR={lr}, BS={batch_size}, Seed={run_seed} ---\")\n", "    set_seed(run_seed)\n", "    \n", "    train_ds, val_ds, _ = datasets\n", "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n", "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n", "    model = ViTForImageClassification.from_pretrained(\n", "        \"nateraw/food\",\n", "        num_labels=num_classes,\n", "        ignore_mismatched_sizes=True\n", "    )\n", "    model.to(DEVICE)\n", "    \n", "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n", "    criterion = nn.CrossEntropyLoss()\n", "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n\n", "    # 2. Training Loop\n", "    last_val_acc = 0.0 # Variable to store the accuracy of the current epoch\n", "    best_val_loss = float('inf') # Only used for Early Stopping patience\n", "    patience_counter = 0 \n", "    for epoch in range(EPOCHS): \n", "        # Train\n", "        model.train()\n", "        running_loss = 0.0\n", "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n", "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n", "            \n", "            optimizer.zero_grad()\n", "            outputs = model(pixel_values=images)\n", "            loss = criterion(outputs.logits, labels)\n", "            loss.backward()\n", "            optimizer.step()\n", "            running_loss += loss.item()\n", "        \n", "        train_loss = running_loss / len(train_loader)\n", "        \n", "        # Validation\n", "        model.eval()\n", "        val_loss = 0.0\n", "        correct = 0\n", "        total = 0\n", "        with torch.no_grad():\n", "            for images, labels in val_loader:\n", "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n", "                outputs = model(pixel_values=images)\n", "                loss = criterion(outputs.logits, labels)\n", "                val_loss += loss.item()\n", "                preds = outputs.logits.argmax(dim=1)\n", "                correct += (preds == labels).sum().item()\n", "                total += labels.size(0)\n", "        val_loss = val_loss / len(val_loader)\n", "        last_val_acc = correct / total # Update with current epoch accuracy\n", "        print(f\"Epoch {epoch+1} \u00e2\u20ac\u201d Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {last_val_acc:.4f}\")\n", "        \n", "        scheduler.step(val_loss)\n\n", "        # Early Stopping Check\n", "        # Note: We are tracking patience based on Loss, but reporting the LAST accuracy.\n", "        if val_loss < best_val_loss:\n", "            best_val_loss = val_loss\n", "            patience_counter = 0\n", "        else:\n", "            patience_counter += 1\n", "            if patience_counter >= PATIENCE: \n", "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n", "                break\n", "    \n", "    training_duration_sec = time.time() - start_time\n", "    print(f\"--- Run Finished: Final (Last) Validation Accuracy = {last_val_acc:.4f} ---\")\n", "    return {\n", "        'last_validation_accuracy': last_val_acc, \n", "        'training_time_sec': training_duration_sec \n", "    }"]}, {"cell_type": "markdown", "metadata": {}, "source": ["======================================================<br>\n", "5. MASTER EXPERIMENT LOOP<br>\n", "======================================================"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\n========================================\")\n", "print(\"STARTING STATISTICAL EXPERIMENT\")\n", "print(\"========================================\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["factors = {\n", "    'lr': [1e-5, 5e-5, 1e-4],\n", "    'batch_size': [16, 32, 64]\n", "}\n", "NUM_REPETITIONS = 15\n", "RESPONSE_VAR_NAME = 'last_validation_accuracy'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["combinations = list(itertools.product(factors['lr'], factors['batch_size']))\n", "total_runs = len(combinations) * NUM_REPETITIONS"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load existing results if available"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_results = []\n", "try:\n", "    if INPUT_CSV_PATH and os.path.exists(INPUT_CSV_PATH):\n", "        all_results = pd.read_csv(INPUT_CSV_PATH).to_dict('records')\n", "        print(f\"Loaded {len(all_results)} existing results.\")\n", "    else:\n", "        print(\"Starting new experiment (no valid input file found).\")\n", "except Exception as e:\n", "    print(f\"Error loading CSV: {e}. Starting fresh.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["run_counter = 0\n", "experiment_start_time = datetime.now()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for rep in range(NUM_REPETITIONS):\n", "    print(f\"\\n====== REPETITION {rep + 1}/{NUM_REPETITIONS} ======\\n\")\n", "    repetition_seed = SEED + rep \n", "    \n", "    for (lr_val, bs_val) in combinations:\n", "        run_counter += 1\n", "        \n", "        # Check if run is already done\n", "        run_done = False\n", "        if all_results:\n", "            for res in all_results:\n", "                if (res['repetition'] == rep + 1 and \n", "                    res['lr'] == lr_val and \n", "                    res['batch_size'] == bs_val and \n", "                    res.get(RESPONSE_VAR_NAME) is not None):\n", "                    run_done = True\n", "                    break\n", "        \n", "        if run_done:\n", "            print(f\"--- [SKIP] Run {run_counter}/{total_runs} already completed.\")\n", "            continue \n\n", "        # Execute Run\n", "        print(f\"--- Running {run_counter}/{total_runs} (Rep {rep+1}, LR={lr_val}, BS={bs_val}) ---\")\n", "        combo_index = combinations.index((lr_val, bs_val))\n", "        run_seed = repetition_seed * 1000 + combo_index\n", "        try:\n", "            metrics = run_experiment(\n", "                lr=lr_val,\n", "                batch_size=bs_val,\n", "                run_seed=run_seed,\n", "                datasets=datasets,\n", "                num_classes=num_classes\n", "            )\n", "            \n", "            result_row = {\n", "                'repetition': rep + 1,\n", "                'lr': lr_val,\n", "                'batch_size': bs_val,\n", "                RESPONSE_VAR_NAME: metrics['last_validation_accuracy'],\n", "                'training_time_sec': metrics['training_time_sec']\n", "            }\n", "            \n", "        except Exception as e:\n", "            print(f\"!!!!!! CRITICAL ERROR in run {run_counter}: {e} !!!!!!\")\n", "            torch.cuda.empty_cache()\n", "            result_row = {\n", "                'repetition': rep + 1,\n", "                'lr': lr_val,\n", "                'batch_size': bs_val,\n", "                RESPONSE_VAR_NAME: None,\n", "                'training_time_sec': None\n", "            }\n", "        \n", "        all_results.append(result_row)\n", "        \n", "        # Save incrementally\n", "        try:\n", "            pd.DataFrame(all_results).to_csv(OUTPUT_CSV_PATH, index=False)\n", "        except Exception as e:\n", "            print(f\"Error saving CSV: {e}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"\\n========================================\")\n", "print(f\"====== EXPERIMENT COMPLETED ======\")\n", "print(f\"Total time: {datetime.now() - experiment_start_time}\")\n", "print(f\"Results saved to: {OUTPUT_CSV_PATH}\")\n", "print(\"========================================\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}